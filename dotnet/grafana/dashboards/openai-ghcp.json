{
  "title": "AI Agent (Copilot Extended) Monitoring Dashboard",
  "description": "Dashboard for monitoring an AI coding assistant (Copilot extension) using OpenTelemetry GenAI metrics",
  "timezone": "browser",
  "refresh": "30s",
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "schemaVersion": 36,
  "version": 1,
  "id": null,
  "tags": [],
  "panels": [
    {
      "id": 1,
      "title": "Token Consumption",
      "type": "timeseries",
      "gridPos": {
        "x": 0,
        "y": 0,
        "w": 12,
        "h": 8
      },
      "fieldConfig": {
        "defaults": {
          "unit": "none",
          "custom": {
            "drawStyle": "line",
            "lineWidth": 2,
            "fillOpacity": 0,
            "showPoints": "never",
            "stacking": { "mode": "none" }
          }
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": "Prometheus",
          "expr": "rate(gen_ai_client_token_usage_sum{gen_ai_token_type=\"input\"}[5m]) / rate(gen_ai_client_token_usage_count{gen_ai_token_type=\"input\"}[5m])",
          "legendFormat": "Input Tokens per Request",
          "refId": "A"
        },
        {
          "datasource": "Prometheus",
          "expr": "rate(gen_ai_client_token_usage_sum{gen_ai_token_type=\"output\"}[5m]) / rate(gen_ai_client_token_usage_count{gen_ai_token_type=\"output\"}[5m])",
          "legendFormat": "Output Tokens per Request",
          "refId": "B"
        }
      ],
      "options": {
        "legend": {
          "showLegend": true,
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": { "mode": "single" }
      }
    },
    {
      "id": 2,
      "title": "Latency Metrics",
      "type": "timeseries",
      "gridPos": {
        "x": 12,
        "y": 0,
        "w": 12,
        "h": 8
      },
      "fieldConfig": {
        "defaults": {
          "unit": "s",
          "decimals": 3,
          "custom": {
            "drawStyle": "line",
            "lineWidth": 2,
            "fillOpacity": 0,
            "showPoints": "never",
            "stacking": { "mode": "none" }
          }
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": "Prometheus",
          "expr": "histogram_quantile(0.5, sum by (le) (rate(gen_ai_client_operation_duration_bucket[5m])))",
          "legendFormat": "Median (p50)",
          "refId": "A"
        },
        {
          "datasource": "Prometheus",
          "expr": "histogram_quantile(0.95, sum by (le) (rate(gen_ai_client_operation_duration_bucket[5m])))",
          "legendFormat": "P95 Latency",
          "refId": "B"
        }
      ],
      "options": {
        "legend": {
          "showLegend": true,
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": { "mode": "single" }
      }
    },
    {
      "id": 3,
      "title": "Error Rates",
      "type": "timeseries",
      "gridPos": {
        "x": 0,
        "y": 8,
        "w": 12,
        "h": 8
      },
      "fieldConfig": {
        "defaults": {
          "unit": "rps",
          "custom": {
            "drawStyle": "line",
            "lineWidth": 1,
            "fillOpacity": 80,
            "showPoints": "never",
            "stacking": { "mode": "normal" }
          }
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": "Prometheus",
          "expr": "sum(rate(gen_ai_client_operation_duration_count{error_type!=\"\"}[5m])) by (error_type)",
          "legendFormat": "{{error_type}}",
          "refId": "A"
        }
      ],
      "options": {
        "legend": {
          "showLegend": true,
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [ "lastNotNull" ]
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      }
    },
    {
      "id": 4,
      "title": "Model Performance",
      "type": "timeseries",
      "gridPos": {
        "x": 12,
        "y": 8,
        "w": 12,
        "h": 8
      },
      "fieldConfig": {
        "defaults": {
          "unit": "s",
          "decimals": 2,
          "custom": {
            "drawStyle": "line",
            "lineWidth": 2,
            "fillOpacity": 0,
            "showPoints": "never",
            "stacking": { "mode": "none" }
          }
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": "Prometheus",
          "expr": "histogram_quantile(0.95, sum by (le, gen_ai_request_model) (rate(gen_ai_client_operation_duration_bucket[5m])))",
          "legendFormat": "{{gen_ai_request_model}} p95",
          "refId": "A"
        }
      ],
      "options": {
        "legend": {
          "showLegend": true,
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [ "lastNotNull" ]
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      }
    },
    {
      "id": 5,
      "title": "User Interaction Analytics",
      "type": "timeseries",
      "gridPos": {
        "x": 0,
        "y": 16,
        "w": 24,
        "h": 8
      },
      "fieldConfig": {
        "defaults": {
          "unit": "rps",
          "custom": {
            "drawStyle": "line",
            "lineWidth": 1,
            "fillOpacity": 70,
            "showPoints": "never",
            "stacking": { "mode": "normal" }
          }
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": "Prometheus",
          "expr": "sum(rate(gen_ai_client_operation_duration_count[5m])) by (gen_ai_operation_name)",
          "legendFormat": "{{gen_ai_operation_name}}",
          "refId": "A"
        }
      ],
      "options": {
        "legend": {
          "showLegend": true,
          "displayMode": "table",
          "placement": "bottom",
          "calcs": [ "lastNotNull" ]
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      }
    }
  ]
}
